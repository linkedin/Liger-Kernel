name: üêõ Bug Report
description: Create a report to help us reproduce and fix the bug

body:
- type: markdown
  attributes:
    value: >
      #### Before submitting a bug, please make sure the issue hasn't been already addressed by searching through [the existing and past issues](https://github.com/triton-lang/triton/issues).
- type: textarea
  attributes:
    label: üêõ Describe the bug
    description: |
      Please provide a clear and concise description of what the bug is.
    placeholder: |
      A clear and concise description of what the bug is.
  validations:
    required: true

- type: textarea
  attributes:
    label: Reproduce
    description: |
      If applicable, add a minimal example so that we can reproduce the error by running the code. 
      It is very important for the snippet to be as succinct (minimal) as possible, so please take time to trim down any irrelevant code to help us debug efficiently. 
      We are going to copy-paste your code and we expect to get the same result as you did: avoid any external data, and include the relevant imports, etc. 
      For example:
      ```python
      # All necessary imports at the beginning
      import torch
      import triton
      import triton.language as tl
      # A succinct reproducing example trimmed down to the essential parts:
      @triton.jit
      def add_kernel(
          x_ptr, 
          y_ptr,
          output_ptr,
          n_elements,
          BLOCK_SIZE # Note: the bug is here, we should pass tl.constexpr
      ):
          pid = tl.program_id(axis=0)
          block_start = pid * BLOCK_SIZE
          offsets = block_start + tl.arange(0, BLOCK_SIZE)
          mask = offsets < n_elements
          x = tl.load(x_ptr + offsets, mask=mask)
          y = tl.load(y_ptr + offsets, mask=mask)
          output = x + y
          tl.store(output_ptr + offsets, output, mask=mask)
      def add(x: torch.Tensor, y: torch.Tensor):
          output = torch.empty_like(x)
          n_elements = output.numel()
          grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )
          add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)
          return output
      x = torch.rand(8, device='cuda')
      y = torch.rand(8, device='cuda')
      output_triton = add(x, y)
      ```
      If the code is too long (hopefully, it isn't), feel free to put it in a public gist and link it in the issue: https://gist.github.com.
      Please also paste or describe the results you observe instead of the expected results. If you observe an error, please paste the error message including the **full** traceback of the exception. It may be relevant to wrap error messages in ```` ```triple quotes blocks``` ````.
    placeholder: |
      A clear and concise description of what the bug is.
      ```python
      # Sample code to reproduce the problem
      ```
      ```
      The error message you got, with the full traceback.
      ```
  validations:
    required: false


- type: textarea
  attributes:
    label: Versions
    description: |
      Please provide triton, torch, hardware, and other necessary versions to reproduce the bug.
  validations:
    required: true
- type: markdown
  attributes:
    value: >
      Thanks for contributing üéâ!
