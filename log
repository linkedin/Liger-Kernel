============================= test session starts ==============================
platform linux -- Python 3.12.7, pytest-8.3.4, pluggy-1.5.0
rootdir: /home/ryan/Documents/GitHub/Liger-Kernel
configfile: pyproject.toml
collected 24 items

test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype0-0.005-0.005-8-128-1024-4096] FAILED [  4%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype0-0.005-0.005-3-47-31-123] FAILED [  8%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] FAILED [ 12%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype1-1e-05-0.0005-3-47-31-123] FAILED [ 16%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype0-0.005-0.005-8-128-1024-4096] FAILED [ 20%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype0-0.005-0.005-3-47-31-123] FAILED [ 25%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] FAILED [ 29%]
test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype1-1e-05-0.0005-3-47-31-123] FAILED [ 33%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype0-0.005-0.005-8-128-1024-4096] FAILED [ 37%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype0-0.005-0.005-3-47-31-123] FAILED [ 41%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] FAILED [ 45%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype1-1e-05-0.0005-3-47-31-123] FAILED [ 50%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype0-0.005-0.005-8-128-1024-4096] FAILED [ 54%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype0-0.005-0.005-3-47-31-123] FAILED [ 58%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] FAILED [ 62%]
test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype1-1e-05-0.0005-3-47-31-123] FAILED [ 66%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[True-1.0-dtype0-0.05-0.5-2-2-8-8] PASSED [ 70%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[True-1.0-dtype0-0.05-0.5-3-47-31-123] PASSED [ 75%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[True-1.0-dtype1-1e-05-0.0005-2-2-8-8] PASSED [ 79%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[True-1.0-dtype1-1e-05-0.0005-3-47-31-123] PASSED [ 83%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[False-1.0-dtype0-0.05-0.5-2-2-8-8] PASSED [ 87%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[False-1.0-dtype0-0.05-0.5-3-47-31-123] PASSED [ 91%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[False-1.0-dtype1-1e-05-0.0005-2-2-8-8] PASSED [ 95%]
test/chunked_loss/test_cpo_loss.py::test_correctness_functional[False-1.0-dtype1-1e-05-0.0005-3-47-31-123] PASSED [100%]

=================================== FAILURES ===================================
__ test_correctness[-100-0.1-1.0-True-1.0-dtype0-0.005-0.005-8-128-1024-4096] __

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = True, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(116.6298, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
____ test_correctness[-100-0.1-1.0-True-1.0-dtype0-0.005-0.005-3-47-31-123] ____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = True, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(16.4326, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
_ test_correctness[-100-0.1-1.0-True-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] __

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = True, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(116.1180, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
___ test_correctness[-100-0.1-1.0-True-1.0-dtype1-1e-05-0.0005-3-47-31-123] ____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = True, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(16.4060, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
_ test_correctness[-100-0.1-1.0-False-1.0-dtype0-0.005-0.005-8-128-1024-4096] __

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = False, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(119.2628, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
___ test_correctness[-100-0.1-1.0-False-1.0-dtype0-0.005-0.005-3-47-31-123] ____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = False, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(15.0560, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
_ test_correctness[-100-0.1-1.0-False-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] _

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = False, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(115.2395, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
___ test_correctness[-100-0.1-1.0-False-1.0-dtype1-1e-05-0.0005-3-47-31-123] ___

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = False, ignore_index = -100, beta = 0.1
alpha = 1.0

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(15.0284, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
__ test_correctness[42-0.2-0.85-True-1.0-dtype0-0.005-0.005-8-128-1024-4096] ___

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = True, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(117.2575, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
----------------------------- Captured stderr call -----------------------------
W1211 23:18:09.758000 217831 site-packages/torch/_dynamo/convert_frame.py:844] [0/8] torch._dynamo hit config.cache_size_limit (8)
W1211 23:18:09.758000 217831 site-packages/torch/_dynamo/convert_frame.py:844] [0/8]    function: 'fused_fwd_bwd' (/home/ryan/Documents/GitHub/Liger-Kernel/src/liger_kernel/chunked_loss/fused_linear_preference.py:103)
W1211 23:18:09.758000 217831 site-packages/torch/_dynamo/convert_frame.py:844] [0/8]    last reason: 0/0: L['compute_loss'].keywords['ignore_index'] == -100          
W1211 23:18:09.758000 217831 site-packages/torch/_dynamo/convert_frame.py:844] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W1211 23:18:09.758000 217831 site-packages/torch/_dynamo/convert_frame.py:844] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
____ test_correctness[42-0.2-0.85-True-1.0-dtype0-0.005-0.005-3-47-31-123] _____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = True, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(15.0183, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
__ test_correctness[42-0.2-0.85-True-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] __

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = True, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(116.7569, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
____ test_correctness[42-0.2-0.85-True-1.0-dtype1-1e-05-0.0005-3-47-31-123] ____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = True, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(16.0889, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
__ test_correctness[42-0.2-0.85-False-1.0-dtype0-0.005-0.005-8-128-1024-4096] __

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = False, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(116.8942, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
____ test_correctness[42-0.2-0.85-False-1.0-dtype0-0.005-0.005-3-47-31-123] ____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.bfloat16
atol = 0.005, rtol = 0.005, bias = False, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(15.8006, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
_ test_correctness[42-0.2-0.85-False-1.0-dtype1-1e-05-0.0005-8-128-1024-4096] __

B = 16, T = 128, H = 1024, V = 4096, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = False, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(115.5728, device='cuda:0',
       grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
___ test_correctness[42-0.2-0.85-False-1.0-dtype1-1e-05-0.0005-3-47-31-123] ____

B = 6, T = 47, H = 31, V = 123, scalar = 1.0, dtype = torch.float32
atol = 1e-05, rtol = 0.0005, bias = False, ignore_index = 42, beta = 0.2
alpha = 0.85

    @pytest.mark.parametrize(
        "B, T, H, V",
        [
            (8, 128, 1024, 4096),
            (3, 47, 31, 123),  # random shape
        ],
    )
    @pytest.mark.parametrize(
        "scalar, dtype, atol, rtol",
        [
            (1.0, torch.bfloat16, 5e-3, 5e-3),
            (1.0, torch.float32, 1e-5, 5e-4),
        ],
    )
    @pytest.mark.parametrize("bias", [True, False])
    @pytest.mark.parametrize(
        "ignore_index, beta, alpha", [(-100, 0.1, 1.0), (42, 0.2, 0.85)]
    )
    def test_correctness(
        B, T, H, V, scalar, dtype, atol, rtol, bias, ignore_index, beta, alpha
    ):
        B = 2 * B  # cpo loss requires B to be even
    
        torch_lm_head_cpo = TorchLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
        liger_lm_head_cpo = LigerLMHeadCPO(
            H=H,
            V=V,
            dtype=dtype,
            bias=bias,
            ignore_index=ignore_index,
            beta=beta,
        )
    
        torch_lm_head_cpo.lin.weight.data = liger_lm_head_cpo.lin.weight.data = torch.randn(
            V, H, device=device, dtype=dtype
        )
    
        if bias:
            torch_lm_head_cpo.lin.bias.data = liger_lm_head_cpo.lin.bias.data = torch.randn(
                V, device=device, dtype=dtype
            )
    
        _input = torch.randn(B, T, H, device=device, dtype=dtype) * scalar
        input1 = _input.detach().clone().requires_grad_(True)
        input2 = _input.detach().clone().requires_grad_(True)
    
        target = torch.randint(
            0,
            V,
            (
                B,
                T,
            ),
            device=device,
            dtype=torch.long,
        )
        # Assign some random number of elements as ignore_index
        num_elements_to_assign = torch.randint(1, B * T // 2, (1,)).item()
        indices_to_assign = torch.randperm(B * T)[:num_elements_to_assign]
        target.view(-1)[indices_to_assign] = ignore_index
    
        loss1, aggregated_aux_outputs1 = torch_lm_head_cpo(input1, target)
        loss2, aggregated_aux_outputs2 = liger_lm_head_cpo(input2, target)
    
        assert_verbose_allclose(loss1, loss2, atol=atol, rtol=rtol)
    
        assert len(aggregated_aux_outputs1) == len(aggregated_aux_outputs2)
    
        for i in range(len(aggregated_aux_outputs1)):
            assert_verbose_allclose(
                aggregated_aux_outputs1[i],
                aggregated_aux_outputs2[i],
                atol=atol,
                rtol=rtol,
            )
    
        loss1.backward()
>       loss2.backward()

test/chunked_loss/test_cpo_loss.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581: in backward
    torch.autograd.backward(
../../../miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347: in backward
    _engine_run_backward(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

t_outputs = (tensor(14.6347, device='cuda:0', grad_fn=<LigerFusedLinearCPOFunctionBackward>),)
args = ((tensor(1., device='cuda:0'),), False, False, ())
kwargs = {'accumulate_grad': True, 'allow_unreachable': True}
attach_logging_hooks = False

    def _engine_run_backward(
        t_outputs: Sequence[Union[torch.Tensor, GradientEdge]],
        *args: Any,
        **kwargs: Any,
    ) -> Tuple[torch.Tensor, ...]:
        attach_logging_hooks = log.getEffectiveLevel() <= logging.DEBUG
        if attach_logging_hooks:
            unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        try:
>           return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                t_outputs, *args, **kwargs
            )  # Calls into the C++ engine to run the backward pass
E           RuntimeError: function LigerFusedLinearCPOFunctionBackward returned an incorrect number of gradients (expected 10, got 9)

../../../miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825: RuntimeError
=============================== warnings summary ===============================
../../../miniconda3/lib/python3.12/site-packages/_pytest/config/__init__.py:1441
  /home/ryan/miniconda3/lib/python3.12/site-packages/_pytest/config/__init__.py:1441: PytestConfigWarning: Unknown config option: asyncio_mode
  
    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype0-0.005-0.005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype0-0.005-0.005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype1-1e-05-0.0005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-True-1.0-dtype1-1e-05-0.0005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype0-0.005-0.005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype0-0.005-0.005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype1-1e-05-0.0005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[-100-0.1-1.0-False-1.0-dtype1-1e-05-0.0005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype0-0.005-0.005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype0-0.005-0.005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype1-1e-05-0.0005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-True-1.0-dtype1-1e-05-0.0005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype0-0.005-0.005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype0-0.005-0.005-3-47-31-123]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype1-1e-05-0.0005-8-128-1024-4096]
FAILED test/chunked_loss/test_cpo_loss.py::test_correctness[42-0.2-0.85-False-1.0-dtype1-1e-05-0.0005-3-47-31-123]
=================== 16 failed, 8 passed, 1 warning in 6.01s ====================
