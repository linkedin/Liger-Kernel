
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Efficient Triton Kernels for LLM Training">
      
      
        <meta name="author" content="LinkedIn">
      
      
        <link rel="canonical" href="https://linkedin.github.io/Liger-Kernel/Examples/">
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../Getting-Started/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>Examples - Liger-Kernel Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather+Sans:300,300i,400,400i,700,700i%7CRed+Hat+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Merriweather Sans";--md-code-font:"Red Hat Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="green" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#huggingface-trainer" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Liger-Kernel Docs" class="md-header__button md-logo" aria-label="Liger-Kernel Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Liger-Kernel Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Examples
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="green" data-md-color-accent="deep-purple"  aria-label="Dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-purple"  aria-label="Light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/linkedin/Liger-Kernel" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    linkedin/Liger-Kernel
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Liger-Kernel Docs" class="md-nav__button md-logo" aria-label="Liger-Kernel Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Liger-Kernel Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/linkedin/Liger-Kernel" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    linkedin/Liger-Kernel
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#huggingface-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      HuggingFace Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HuggingFace Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU machine
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remotely-on-modal" class="md-nav__link">
    <span class="md-ellipsis">
      Remotely on Modal
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-result" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Result
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama" class="md-nav__link">
    <span class="md-ellipsis">
      Llama
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qwen" class="md-nav__link">
    <span class="md-ellipsis">
      Qwen
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gemma-7b" class="md-nav__link">
    <span class="md-ellipsis">
      Gemma 7B
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightning-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Lightning Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lightning Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run_1" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine_1" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#medusa" class="md-nav__link">
    <span class="md-ellipsis">
      Medusa
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Medusa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run_2" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-result_1" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Result
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Benchmark Result">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stage-1" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-3" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-5" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-2" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-3_1" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-5_1" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 5
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-language-model-sft" class="md-nav__link">
    <span class="md-ellipsis">
      Vision-Language Model SFT
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-run_3" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine_2" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU Machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orpo-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      ORPO Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ORPO Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run_4" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine_3" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU Machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Getting-Started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../High-Level-APIs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    High Level APIs
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Low-Level-APIs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Low Level APIs
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../acknowledgement/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Acknowledgment
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../license/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    License
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#huggingface-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      HuggingFace Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HuggingFace Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU machine
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remotely-on-modal" class="md-nav__link">
    <span class="md-ellipsis">
      Remotely on Modal
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-result" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Result
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama" class="md-nav__link">
    <span class="md-ellipsis">
      Llama
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qwen" class="md-nav__link">
    <span class="md-ellipsis">
      Qwen
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gemma-7b" class="md-nav__link">
    <span class="md-ellipsis">
      Gemma 7B
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightning-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Lightning Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lightning Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run_1" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine_1" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#medusa" class="md-nav__link">
    <span class="md-ellipsis">
      Medusa
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Medusa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run_2" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-result_1" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Result
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Benchmark Result">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stage-1" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-3" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-5" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-2" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-3_1" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_head-5_1" class="md-nav__link">
    <span class="md-ellipsis">
      num_head = 5
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-language-model-sft" class="md-nav__link">
    <span class="md-ellipsis">
      Vision-Language Model SFT
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-run_3" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine_2" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU Machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#orpo-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      ORPO Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ORPO Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-to-run_4" class="md-nav__link">
    <span class="md-ellipsis">
      How to Run
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to Run">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#locally-on-a-gpu-machine_3" class="md-nav__link">
    <span class="md-ellipsis">
      Locally on a GPU Machine
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Examples</h1>

<div class="admonition example">
<p class="admonition-title">HANDS-ON USECASE EXAMPLES</p>
</div>
<table>
<thead>
<tr>
<th><strong>Use Case</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/linkedin/Liger-Kernel/tree/main/examples/huggingface"><strong>Hugging Face Trainer</strong></a></td>
<td>Train LLaMA 3-8B ~20% faster with over 40% memory reduction on Alpaca dataset using 4 A100s with FSDP</td>
</tr>
<tr>
<td><a href="https://github.com/linkedin/Liger-Kernel/tree/main/examples/lightning"><strong>Lightning Trainer</strong></a></td>
<td>Increase 15% throughput and reduce memory usage by 40% with LLaMA3-8B on MMLU dataset using 8 A100s with DeepSpeed ZeRO3</td>
</tr>
<tr>
<td><a href="https://github.com/linkedin/Liger-Kernel/tree/main/examples/medusa"><strong>Medusa Multi-head LLM (Retraining Phase)</strong></a></td>
<td>Reduce memory usage by 80% with 5 LM heads and improve throughput by 40% using 8 A100s with FSDP</td>
</tr>
<tr>
<td><a href="https://github.com/linkedin/Liger-Kernel/tree/main/examples/huggingface/run_qwen2_vl.sh"><strong>Vision-Language Model SFT</strong></a></td>
<td>Finetune Qwen2-VL on image-text data using 4 A100s with FSDP</td>
</tr>
<tr>
<td><a href="https://github.com/linkedin/Liger-Kernel/blob/main/examples/alignment/run_orpo.py"><strong>Liger ORPO Trainer</strong></a></td>
<td>Align Llama 3.2 using Liger ORPO Trainer with FSDP with 50% memory reduction</td>
</tr>
</tbody>
</table>
<h2 id="huggingface-trainer">HuggingFace Trainer<a class="headerlink" href="#huggingface-trainer" title="Permanent link">&para;</a></h2>
<h3 id="how-to-run">How to Run<a class="headerlink" href="#how-to-run" title="Permanent link">&para;</a></h3>
<h4 id="locally-on-a-gpu-machine">Locally on a GPU machine<a class="headerlink" href="#locally-on-a-gpu-machine" title="Permanent link">&para;</a></h4>
<p>You can run the example locally on a GPU machine. The default hyperparameters and configurations work on single node with 4xA100 80GB GPUs and FSDP.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>sh<span class="w"> </span>run_<span class="o">{</span>MODEL<span class="o">}</span>.sh
</span></code></pre></div>
<h4 id="remotely-on-modal">Remotely on Modal<a class="headerlink" href="#remotely-on-modal" title="Permanent link">&para;</a></h4>
<p>If you do not have access to a GPU machine, you can run the example on Modal. Modal is a serverless platform that allows you to run your code on a remote GPU machine. You can sign up for a free account at <a href="https://www.modal.com/">Modal</a>.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>pip<span class="w"> </span>install<span class="w"> </span>modal
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>modal<span class="w"> </span>setup<span class="w">  </span><span class="c1"># authenticate with Modal</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>modal<span class="w"> </span>run<span class="w"> </span>launch_on_modal.py<span class="w"> </span>--script<span class="w"> </span><span class="s2">&quot;run_qwen2_vl.sh&quot;</span>
</span></code></pre></div>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
</div>
<ol>
<li>
<p>This example uses an optional <code>use_liger</code> flag. If true, it does a 1 line monkey patch to apply liger kernel.</p>
</li>
<li>
<p>The example uses Llama3 model that requires community license agreement and HuggingFace Hub login. If you want to use Llama3 in this example, please make sure you have done the following:</p>
<ul>
<li>Agree on the <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B">community license agreement</a> .</li>
<li>Run <code>huggingface-cli login</code> and enter your HuggingFace token.</li>
</ul>
</li>
<li>
<p>The default hyperparameters and configurations work on single node with 4xA100 80GB GPUs. For running on device with less GPU RAM, please consider reducing the per-GPU batch size and/or enable <code>CPUOffload</code> in FSDP.</p>
</li>
</ol>
<h3 id="benchmark-result">Benchmark Result<a class="headerlink" href="#benchmark-result" title="Permanent link">&para;</a></h3>
<h3 id="llama">Llama<a class="headerlink" href="#llama" title="Permanent link">&para;</a></h3>
<div class="admonition info">
<p class="admonition-title">Info</p>
</div>
<blockquote>
<p>Benchmark conditions: 
Model= LLaMA 3-8B,Datset= Alpaca, Max seq len = 512, Data Type = bf16, Optimizer = AdamW, Gradient Checkpointing = True, Distributed Strategy = FSDP1 on 4 A100s.</p>
</blockquote>
<p>Throughput improves by around 20%, while GPU memory usage drops by 40%. This allows you to train the model on smaller GPUs, use larger batch sizes, or handle longer sequence lengths without incurring additional costs.</p>
<p><img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/huggingface/img/llama_tps.png" />
<img alt="GPU Memory Allocated" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/huggingface/img/llama_mem_alloc.png" /></p>
<h3 id="qwen">Qwen<a class="headerlink" href="#qwen" title="Permanent link">&para;</a></h3>
<div class="admonition info">
<p class="admonition-title">Info</p>
</div>
<blockquote>
<p>Benchmark conditions:
Model= Qwen2-7B, Dataset= Alpaca, Max seq len = 512, Data Type = bf16, Optimizer = AdamW, Gradient Checkpointing = True, Distributed Strategy = FSDP1 on 4 A100s.</p>
</blockquote>
<p>Throughput improves by around 10%, while GPU memory usage drops by 50%.</p>
<p><img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/huggingface/img/qwen_tps.png" />
<img alt="GPU Memory Allocated" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/huggingface/img/qwen_mem_alloc.png" /></p>
<h3 id="gemma-7b">Gemma 7B<a class="headerlink" href="#gemma-7b" title="Permanent link">&para;</a></h3>
<div class="admonition info">
<p class="admonition-title">Info</p>
</div>
<blockquote>
<p>Benchmark conditions:
Model= Gemma-7B, Dataset= Alpaca, Max seq len = 512, Data Type = bf16, Optimizer = AdamW, Gradient Checkpointing = True, Distributed Strategy = FSDP1 on 4 A100s.</p>
</blockquote>
<p>Throughput improves by around 24%, while GPU memory usage drops by 33%.</p>
<p><img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/huggingface/img/gemma_7b_mem.png" />
<img alt="GPU Memory Allocated" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/huggingface/img/gemma_7b_tp.png" /></p>
<h2 id="lightning-trainer">Lightning Trainer<a class="headerlink" href="#lightning-trainer" title="Permanent link">&para;</a></h2>
<h3 id="how-to-run_1">How to Run<a class="headerlink" href="#how-to-run_1" title="Permanent link">&para;</a></h3>
<h4 id="locally-on-a-gpu-machine_1">Locally on a GPU machine<a class="headerlink" href="#locally-on-a-gpu-machine_1" title="Permanent link">&para;</a></h4>
<p>You can run the example locally on a GPU machine.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="c1"># For single L40 48GB GPU</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>python<span class="w"> </span>training.py<span class="w"> </span>--model<span class="w"> </span>Qwen/Qwen2-0.5B-Instruct<span class="w"> </span>--num_gpu<span class="w"> </span><span class="m">1</span><span class="w"> </span>--max_length<span class="w"> </span><span class="m">1024</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="c1"># For 8XA100 40GB</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>python<span class="w"> </span>training.py<span class="w"> </span>--model<span class="w"> </span>meta-llama/Meta-Llama-3-8B<span class="w"> </span>--strategy<span class="w"> </span>deepspeed
</span></code></pre></div>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
</div>
<ol>
<li>
<p>The example uses Llama3 model that requires community license agreement and HuggingFace Hub login. If you want to use Llama3 in this example, please make sure you have done the following:</p>
<ul>
<li>Agree on the <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B">community license agreement</a></li>
<li>Run <code>huggingface-cli login</code> and enter your HuggingFace token.</li>
</ul>
</li>
<li>
<p>The default hyperparameters and configurations for gemma works on single L40 48GB GPU and config for llama work on single node with 8xA100 40GB GPUs. For running on device with less GPU RAM, please consider reducing the per-GPU batch size and/or enable <code>CPUOffload</code> in FSDP.</p>
</li>
</ol>
<h2 id="medusa">Medusa<a class="headerlink" href="#medusa" title="Permanent link">&para;</a></h2>
<p>Medusa is a simple framework that democratizes the acceleration techniques for LLM generation with multiple decoding heads. To know more, you can check out the <a href="https://arxiv.org/abs/2401.10774">repo</a> and the <a href="https://arxiv.org/abs/2401.10774">paper</a> .</p>
<p>The Liger fused CE kernel is highly effective in this scenario, eliminating the need to materialize logits for each head, which usually consumes a large volume of memory due to the extensive vocabulary size (e.g., for LLaMA-3, the vocabulary size is 128k).</p>
<p>The introduction of multiple heads can easily lead to OOM (Out of Memory) issues. However, thanks to the efficient Liger fused CE, which calculates the gradient in place and doesn't materialize the logits, we have observed very effective results. This efficiency opens up more opportunities for multi-token prediction research and development.</p>
<h3 id="how-to-run_2">How to Run<a class="headerlink" href="#how-to-run_2" title="Permanent link">&para;</a></h3>
<div class="admonition example">
<p class="admonition-title">Example</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>git<span class="w"> </span>clone<span class="w"> </span>git@github.com:linkedin/Liger-Kernel.git
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="nb">cd</span><span class="w"> </span><span class="o">{</span>PATH_TO_Liger-Kernel<span class="o">}</span>/Liger-Kernel/
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="nb">cd</span><span class="w"> </span><span class="o">{</span>PATH_TO_Liger-Kernel<span class="o">}</span>/Liger-Kernel/examples/medusa
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>sh<span class="w"> </span>scripts/llama3_8b_medusa.sh
</span></code></pre></div>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
</div>
<ol>
<li>
<p>This example uses an optional <code>use_liger</code> flag. If true, it does a monkey patch to apply liger kernel with medusa heads.</p>
</li>
<li>
<p>The example uses Llama3 model that requires community license agreement and HuggingFace Hub login. If you want to use Llama3 in this example, please make sure you have done the followings:</p>
<ul>
<li>Agree on the community license agreement https://huggingface.co/meta-llama/Meta-Llama-3-8B</li>
<li>Run <code>huggingface-cli login</code> and enter your HuggingFace token</li>
</ul>
</li>
<li>
<p>The default hyperparameters and configurations work on single node with 8xA100 GPUs. For running on device with less GPU RAM, please consider reducing the per-GPU batch size and/or enable <code>CPUOffload</code> in FSDP.</p>
</li>
<li>
<p>We are using a smaller sample of shared GPT data primarily to benchmark performance. The example requires hyperparameter tuning and dataset selection to work effectively, also ensuring the dataset has the same distribution as the LLaMA pretraining data. Welcome contribution to enhance the example code.</p>
</li>
</ol>
<h3 id="benchmark-result_1">Benchmark Result<a class="headerlink" href="#benchmark-result_1" title="Permanent link">&para;</a></h3>
<div class="admonition info">
<p class="admonition-title">Info</p>
</div>
<blockquote>
<ol>
<li>Benchmark conditions: LLaMA 3-8B, Batch Size = 6, Data Type = bf16, Optimizer = AdamW, Gradient Checkpointing = True, Distributed Strategy = FSDP1 on 8 A100s.</li>
</ol>
</blockquote>
<h4 id="stage-1">Stage 1<a class="headerlink" href="#stage-1" title="Permanent link">&para;</a></h4>
<p>Stage 1 refers to Medusa-1 where the backbone model is frozen and only weights of LLM heads are updated.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1"># Modify this flag in llama3_8b_medusa.sh to True enables stage1 </span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>--medusa_only_heads<span class="w"> </span>True
</span></code></pre></div>
<h4 id="num_head-3">num_head = 3<a class="headerlink" href="#num_head-3" title="Permanent link">&para;</a></h4>
<p><img alt="Memory" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Memory_Stage1_num_head_3.png" />
<img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Throughput_Stage1_num_head_3.png" /></p>
<h4 id="num_head-5">num_head = 5<a class="headerlink" href="#num_head-5" title="Permanent link">&para;</a></h4>
<p><img alt="Memory" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Memory_Stage1_num_head_5.png" />
<img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Throughput_Stage1_num_head_5.png" /></p>
<h4 id="stage-2">Stage 2<a class="headerlink" href="#stage-2" title="Permanent link">&para;</a></h4>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># Modify this flag to False in llama3_8b_medusa.sh enables stage2</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>--medusa_only_heads<span class="w"> </span>False
</span></code></pre></div>
<p>Stage 2 refers to Medusa-2 where all the model weights are updated including the backbone model and llm heads.</p>
<h4 id="num_head-3_1">num_head = 3<a class="headerlink" href="#num_head-3_1" title="Permanent link">&para;</a></h4>
<p><img alt="Memory" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Memory_Stage2_num_head_3.png" />
<img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Throughput_Stage2_num_head_3.png" /></p>
<h4 id="num_head-5_1">num_head = 5<a class="headerlink" href="#num_head-5_1" title="Permanent link">&para;</a></h4>
<p><img alt="Memory" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Memory_Stage2_num_head_5.png" />
<img alt="Throughput" src="https://raw.githubusercontent.com/linkedin/Liger-Kernel/main/examples/medusa/docs/images/Throughput_Stage2_num_head_5.png" /></p>
<h2 id="vision-language-model-sft">Vision-Language Model SFT<a class="headerlink" href="#vision-language-model-sft" title="Permanent link">&para;</a></h2>
<h2 id="how-to-run_3">How to Run<a class="headerlink" href="#how-to-run_3" title="Permanent link">&para;</a></h2>
<h3 id="locally-on-a-gpu-machine_2">Locally on a GPU Machine<a class="headerlink" href="#locally-on-a-gpu-machine_2" title="Permanent link">&para;</a></h3>
<p>You can run the example locally on a GPU machine. The default hyperparameters and configurations work on single node with 4xA100 80GB GPUs.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="ch">#!/bin/bash</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>torchrun<span class="w"> </span>--nnodes<span class="o">=</span><span class="m">1</span><span class="w"> </span>--nproc-per-node<span class="o">=</span><span class="m">4</span><span class="w"> </span>training_multimodal.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">    </span>--model_name<span class="w"> </span><span class="s2">&quot;Qwen/Qwen2-VL-7B-Instruct&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="w">    </span>--bf16<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="w">    </span>--eval_strategy<span class="w"> </span><span class="s2">&quot;no&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span class="w">    </span>--save_strategy<span class="w"> </span><span class="s2">&quot;no&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a><span class="w">    </span>--learning_rate<span class="w"> </span>6e-6<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="w">    </span>--weight_decay<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a><span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a><span class="w">    </span>--lr_scheduler_type<span class="w"> </span><span class="s2">&quot;cosine&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a><span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a><span class="w">    </span>--include_num_input_tokens_seen<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a><span class="w">    </span>--report_to<span class="w"> </span>none<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a><span class="w">    </span>--fsdp<span class="w"> </span><span class="s2">&quot;full_shard auto_wrap&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a><span class="w">    </span>--fsdp_config<span class="w"> </span>config/fsdp_config.json<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a><span class="w">    </span>--seed<span class="w"> </span><span class="m">42</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a><span class="w">    </span>--use_liger<span class="w"> </span>True<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a><span class="w">    </span>--output_dir<span class="w"> </span>multimodal_finetuning
</span></code></pre></div>
<h2 id="orpo-trainer">ORPO Trainer<a class="headerlink" href="#orpo-trainer" title="Permanent link">&para;</a></h2>
<h3 id="how-to-run_4">How to Run<a class="headerlink" href="#how-to-run_4" title="Permanent link">&para;</a></h3>
<h4 id="locally-on-a-gpu-machine_3">Locally on a GPU Machine<a class="headerlink" href="#locally-on-a-gpu-machine_3" title="Permanent link">&para;</a></h4>
<p>You can run the example locally on a GPU machine and FSDP.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
</div>
<div class="language-py highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">ORPOConfig</span>  <span class="c1"># noqa: F401</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="kn">from</span><span class="w"> </span><span class="nn">liger_kernel.transformers.trainer</span><span class="w"> </span><span class="kn">import</span> <span class="n">LigerORPOTrainer</span>  <span class="c1"># noqa: F401</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>    <span class="s2">&quot;meta-llama/Llama-3.2-1B-Instruct&quot;</span><span class="p">,</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="p">)</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>    <span class="s2">&quot;meta-llama/Llama-3.2-1B-Instruct&quot;</span><span class="p">,</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>    <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>    <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a><span class="p">)</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;trl-lib/tldr-preference&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a>
</span><span id="__span-7-22"><a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a><span class="n">training_args</span> <span class="o">=</span> <span class="n">ORPOConfig</span><span class="p">(</span>
</span><span id="__span-7-23"><a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a>    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;Llama3.2_1B_Instruct&quot;</span><span class="p">,</span>
</span><span id="__span-7-24"><a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a>    <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-7-25"><a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a>    <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span id="__span-7-26"><a id="__codelineno-7-26" name="__codelineno-7-26" href="#__codelineno-7-26"></a>    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span><span id="__span-7-27"><a id="__codelineno-7-27" name="__codelineno-7-27" href="#__codelineno-7-27"></a>    <span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-7-28"><a id="__codelineno-7-28" name="__codelineno-7-28" href="#__codelineno-7-28"></a>    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;no&quot;</span><span class="p">,</span>
</span><span id="__span-7-29"><a id="__codelineno-7-29" name="__codelineno-7-29" href="#__codelineno-7-29"></a><span class="p">)</span>
</span><span id="__span-7-30"><a id="__codelineno-7-30" name="__codelineno-7-30" href="#__codelineno-7-30"></a>
</span><span id="__span-7-31"><a id="__codelineno-7-31" name="__codelineno-7-31" href="#__codelineno-7-31"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">LigerORPOTrainer</span><span class="p">(</span>
</span><span id="__span-7-32"><a id="__codelineno-7-32" name="__codelineno-7-32" href="#__codelineno-7-32"></a>    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span>
</span><span id="__span-7-33"><a id="__codelineno-7-33" name="__codelineno-7-33" href="#__codelineno-7-33"></a><span class="p">)</span>
</span><span id="__span-7-34"><a id="__codelineno-7-34" name="__codelineno-7-34" href="#__codelineno-7-34"></a>
</span><span id="__span-7-35"><a id="__codelineno-7-35" name="__codelineno-7-35" href="#__codelineno-7-35"></a><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href=".." class="md-footer__link md-footer__link--prev" aria-label="Previous: Home">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Home
              </div>
            </div>
          </a>
        
        
          
          <a href="../Getting-Started/" class="md-footer__link md-footer__link--next" aria-label="Next: Getting Started">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Getting Started
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/linkedin/Liger-Kernel" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.footer", "toc.follow", "navigation.top", "navigation.sections"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>